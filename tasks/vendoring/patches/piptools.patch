diff --git a/pipenv/patched/piptools/__init__.py b/pipenv/patched/piptools/__init__.py
index e69de29..33dc3e7 100644
--- a/pipenv/patched/piptools/__init__.py
+++ b/pipenv/patched/piptools/__init__.py
@@ -0,0 +1,5 @@
+import os
+import sys
+
+v_path = os.path.abspath(os.path.sep.join([os.path.dirname(os.path.realpath(__file__)), '..']))
+sys.path.insert(0, v_path)
diff --git a/pipenv/patched/piptools/locations.py b/pipenv/patched/piptools/locations.py
index aa0610b..5791f0f 100644
--- a/pipenv/patched/piptools/locations.py
+++ b/pipenv/patched/piptools/locations.py
@@ -2,10 +2,13 @@ import os
 from shutil import rmtree
 
 from .click import secho
-from pip.utils.appdirs import user_cache_dir
+# Patch by vphilippon 2017-11-22: Use pipenv cache path.
+# from pip9.utils.appdirs import user_cache_dir
+from pipenv.environments import PIPENV_CACHE_DIR
 
 # The user_cache_dir helper comes straight from pip itself
-CACHE_DIR = user_cache_dir('pip-tools')
+# CACHE_DIR = user_cache_dir(os.path.join('pip-tools'))
+CACHE_DIR = PIPENV_CACHE_DIR
 
 # NOTE
 # We used to store the cache dir under ~/.pip-tools, which is not the
diff --git a/pipenv/patched/piptools/repositories/base.py b/pipenv/patched/piptools/repositories/base.py
index b791eab..69835c0 100644
--- a/pipenv/patched/piptools/repositories/base.py
+++ b/pipenv/patched/piptools/repositories/base.py
@@ -3,6 +3,7 @@ from __future__ import (absolute_import, division, print_function,
                         unicode_literals)
 
 from abc import ABCMeta, abstractmethod
+from contextlib import contextmanager
 
 from six import add_metaclass
 
@@ -38,3 +39,10 @@ class BaseRepository(object):
         all of the files for a given requirement. It is not acceptable for an
         editable or unpinned requirement to be passed to this function.
         """
+
+    @abstractmethod
+    @contextmanager
+    def allow_all_wheels(self):
+        """
+        Monkey patches pip9.Wheel to allow wheels from all platforms and Python versions.
+        """
diff --git a/pipenv/patched/piptools/repositories/local.py b/pipenv/patched/piptools/repositories/local.py
index ea3a39b..8b30052 100644
--- a/pipenv/patched/piptools/repositories/local.py
+++ b/pipenv/patched/piptools/repositories/local.py
@@ -2,6 +2,8 @@
 from __future__ import (absolute_import, division, print_function,
                         unicode_literals)
 
+from contextlib import contextmanager
+
 from piptools.utils import as_tuple, key_from_req, make_install_requirement
 from .base import BaseRepository
 
@@ -63,3 +65,8 @@ class LocalRequirementsRepository(BaseRepository):
 
     def get_hashes(self, ireq):
         return self.repository.get_hashes(ireq)
+
+    @contextmanager
+    def allow_all_wheels(self):
+        with self.repository.allow_all_wheels():
+            yield
diff --git a/pipenv/patched/piptools/repositories/pypi.py b/pipenv/patched/piptools/repositories/pypi.py
index 598fc97..e84e867 100644
--- a/pipenv/patched/piptools/repositories/pypi.py
+++ b/pipenv/patched/piptools/repositories/pypi.py
@@ -7,12 +7,16 @@ import os
 from contextlib import contextmanager
 from shutil import rmtree
 
-from pip.download import is_file_url, url_to_path
-from pip.index import PackageFinder
-from pip.req.req_set import RequirementSet
-from pip.wheel import Wheel
+from notpip.download import is_file_url, url_to_path
+from notpip.index import PackageFinder
+from notpip.req.req_set import RequirementSet
+from notpip.wheel import Wheel
+from notpip.req.req_install import InstallRequirement
+from pip9._vendor.packaging.requirements import InvalidRequirement
+from pip9._vendor.pyparsing import ParseException
+from notpip.download import SafeFileCache
 try:
-    from pip.utils.hashes import FAVORITE_HASH
+    from notpip.utils.hashes import FAVORITE_HASH
 except ImportError:
     FAVORITE_HASH = 'sha256'
 
@@ -27,23 +31,42 @@ try:
 except ImportError:
     from .._compat import TemporaryDirectory
 
+from pipenv.environments import PIPENV_CACHE_DIR
 
-# Monkey patch pip's Wheel class to support all platform tags. This allows
-# pip-tools to generate hashes for all available distributions, not only the
-# one for the current platform.
 
-def _wheel_supported(self, tags=None):
-    # Ignore current platform. Support everything.
-    return True
+class HashCache(SafeFileCache):
+    """Caches hashes of PyPI artifacts so we do not need to re-download them
 
+    Hashes are only cached when the URL appears to contain a hash in it (and the cache key includes
+    the hash value returned from the server). This ought to avoid issues where the location on the
+    server changes."""
+    def __init__(self, *args, **kwargs):
+        session = kwargs.pop('session')
+        self.session = session
+        kwargs.setdefault('directory', os.path.join(PIPENV_CACHE_DIR, 'hash-cache'))
+        super(HashCache, self).__init__(*args, **kwargs)
+
+    def get_hash(self, location):
+        # if there is no location hash (i.e., md5 / sha256 / etc) we don't want to store it
+        hash_value = None
+        can_hash = location.hash
+        if can_hash:
+            # hash url WITH fragment
+            hash_value = self.get(location.url)
+        if not hash_value:
+            hash_value = self._get_file_hash(location)
+            hash_value = hash_value.encode('utf8')
+        if can_hash:
+            self.set(location.url, hash_value)
+        return hash_value.decode('utf8')
 
-def _wheel_support_index_min(self, tags=None):
-    # All wheels are equal priority for sorting.
-    return 0
-
+    def _get_file_hash(self, location):
+        h = hashlib.new(FAVORITE_HASH)
+        with open_local_or_remote_file(location, self.session) as fp:
+            for chunk in iter(lambda: fp.read(8096), b""):
+                h.update(chunk)
+        return ":".join([FAVORITE_HASH, h.hexdigest()])
 
-Wheel.supported = _wheel_supported
-Wheel.support_index_min = _wheel_support_index_min
 
 
 class PyPIRepository(BaseRepository):
@@ -55,8 +78,9 @@ class PyPIRepository(BaseRepository):
     config), but any other PyPI mirror can be used if index_urls is
     changed/configured on the Finder.
     """
-    def __init__(self, pip_options, session):
+    def __init__(self, pip_options, session, use_json=False):
         self.session = session
+        self.use_json = use_json
 
         index_urls = [pip_options.index_url] + pip_options.extra_index_urls
         if pip_options.no_index:
@@ -81,6 +105,10 @@ class PyPIRepository(BaseRepository):
         # of all secondary dependencies for the given requirement, so we
         # only have to go to disk once for each requirement
         self._dependencies_cache = {}
+        self._json_dep_cache = {}
+
+        # stores *full* path + fragment => sha256
+        self._hash_cache = HashCache(session=session)
 
         # Setup file paths
         self.freshen_build_caches()
@@ -122,6 +150,7 @@ class PyPIRepository(BaseRepository):
         Returns a Version object that indicates the best match for the given
         InstallRequirement according to the external repository.
         """
+
         if ireq.editable:
             return ireq  # return itself as the best match
 
@@ -137,19 +166,79 @@ class PyPIRepository(BaseRepository):
         best_candidate = max(matching_candidates, key=self.finder._candidate_sort_key)
 
         # Turn the candidate into a pinned InstallRequirement
-        return make_install_requirement(
-            best_candidate.project, best_candidate.version, ireq.extras, constraint=ireq.constraint
+        new_req = make_install_requirement(
+            best_candidate.project, best_candidate.version, ireq.extras, ireq.markers, constraint=ireq.constraint
         )
 
+        # KR TODO: Marker here?
+
+        return new_req
+
+    def get_json_dependencies(self, ireq):
+
+        if not (is_pinned_requirement(ireq)):
+            raise TypeError('Expected pinned InstallRequirement, got {}'.format(ireq))
+
+        def gen(ireq):
+            if self.DEFAULT_INDEX_URL in self.finder.index_urls:
+
+                url = 'https://pypi.org/pypi/{0}/json'.format(ireq.req.name)
+                r = self.session.get(url)
+
+                # TODO: Latest isn't always latest.
+                latest = list(r.json()['releases'].keys())[-1]
+                if str(ireq.req.specifier) == '=={0}'.format(latest):
+
+                    for requires in r.json().get('info', {}).get('requires_dist', {}):
+                        i = InstallRequirement.from_line(requires)
+
+                        if 'extra' not in repr(i.markers):
+                            yield i
+
+        try:
+            if ireq not in self._json_dep_cache:
+                self._json_dep_cache[ireq] = [g for g in gen(ireq)]
+
+            return set(self._json_dep_cache[ireq])
+        except Exception:
+            return set()
+
     def get_dependencies(self, ireq):
+        json_results = set()
+
+        if self.use_json:
+            try:
+                json_results = self.get_json_dependencies(ireq)
+            except TypeError:
+                json_results = set()
+
+        legacy_results = self.get_legacy_dependencies(ireq)
+        json_results.update(legacy_results)
+
+        return json_results
+
+    def get_legacy_dependencies(self, ireq):
         """
         Given a pinned or an editable InstallRequirement, returns a set of
         dependencies (also InstallRequirements, but not necessarily pinned).
         They indicate the secondary dependencies for the given requirement.
         """
+
         if not (ireq.editable or is_pinned_requirement(ireq)):
             raise TypeError('Expected pinned or editable InstallRequirement, got {}'.format(ireq))
 
+        # Collect setup_requires info from local eggs.
+        setup_requires = {}
+        if ireq.editable:
+            try:
+                dist = ireq.get_dist()
+                if dist.has_metadata('requires.txt'):
+                    setup_requires = self.finder.get_extras_links(
+                        dist.get_metadata_lines('requires.txt')
+                    )
+            except TypeError:
+                pass
+
         if ireq not in self._dependencies_cache:
             if ireq.link and not ireq.link.is_artifact:
                 # No download_dir for VCS sources.  This also works around pip
@@ -166,8 +255,43 @@ class PyPIRepository(BaseRepository):
                                     self.source_dir,
                                     download_dir=download_dir,
                                     wheel_download_dir=self._wheel_download_dir,
-                                    session=self.session)
-            self._dependencies_cache[ireq] = reqset._prepare_file(self.finder, ireq)
+                                    session=self.session,
+                                    ignore_installed=True,
+                                    ignore_compatibility=False
+                                    )
+
+            result = reqset._prepare_file(self.finder, ireq, ignore_requires_python=True)
+
+            # Convert setup_requires dict into a somewhat usable form.
+            if setup_requires:
+                for section in setup_requires:
+                    python_version = section
+                    not_python = not (section.startswith('[') and ':' in section)
+
+                    for value in setup_requires[section]:
+                        # This is a marker.
+                        if value.startswith('[') and ':' in value:
+                            python_version = value[1:-1]
+                            not_python = False
+                        # Strip out other extras.
+                        if value.startswith('[') and ':' not in value:
+                            not_python = True
+
+                        if ':' not in value:
+                            try:
+                                if not not_python:
+                                    result = result + [InstallRequirement.from_line("{0}{1}".format(value, python_version).replace(':', ';'))]
+                            # Anything could go wrong here â€” can't be too careful.
+                            except Exception:
+                                pass
+
+            if reqset.requires_python:
+
+                marker = 'python_version=="{0}"'.format(reqset.requires_python.replace(' ', ''))
+                new_req = InstallRequirement.from_line('{0}; {1}'.format(str(ireq.req), marker))
+                result = [new_req]
+
+            self._dependencies_cache[ireq] = result
         return set(self._dependencies_cache[ireq])
 
     def get_hashes(self, ireq):
@@ -182,24 +306,47 @@ class PyPIRepository(BaseRepository):
 
         # We need to get all of the candidates that match our current version
         # pin, these will represent all of the files that could possibly
-        # satisify this constraint.
+        # satisfy this constraint.
         all_candidates = self.find_all_candidates(ireq.name)
         candidates_by_version = lookup_table(all_candidates, key=lambda c: c.version)
         matching_versions = list(
             ireq.specifier.filter((candidate.version for candidate in all_candidates)))
         matching_candidates = candidates_by_version[matching_versions[0]]
-
         return {
-            self._get_file_hash(candidate.location)
+            self._hash_cache.get_hash(candidate.location)
             for candidate in matching_candidates
         }
 
-    def _get_file_hash(self, location):
-        h = hashlib.new(FAVORITE_HASH)
-        with open_local_or_remote_file(location, self.session) as fp:
-            for chunk in iter(lambda: fp.read(8096), b""):
-                h.update(chunk)
-        return ":".join([FAVORITE_HASH, h.hexdigest()])
+    @contextmanager
+    def allow_all_wheels(self):
+        """
+        Monkey patches pip9.Wheel to allow wheels from all platforms and Python versions.
+
+        This also saves the candidate cache and set a new one, or else the results from the
+        previous non-patched calls will interfere.
+        """
+        def _wheel_supported(self, tags=None):
+            # Ignore current platform. Support everything.
+            return True
+
+        def _wheel_support_index_min(self, tags=None):
+            # All wheels are equal priority for sorting.
+            return 0
+
+        original_wheel_supported = Wheel.supported
+        original_support_index_min = Wheel.support_index_min
+        original_cache = self._available_candidates_cache
+
+        Wheel.supported = _wheel_supported
+        Wheel.support_index_min = _wheel_support_index_min
+        self._available_candidates_cache = {}
+
+        try:
+            yield
+        finally:
+            Wheel.supported = original_wheel_supported
+            Wheel.support_index_min = original_support_index_min
+            self._available_candidates_cache = original_cache
 
 
 @contextmanager
@@ -207,7 +354,7 @@ def open_local_or_remote_file(link, session):
     """
     Open local or remote file for reading.
 
-    :type link: pip.index.Link
+    :type link: pip9.index.Link
     :type session: requests.Session
     :raises ValueError: If link points to a local directory.
     :return: a context manager to the opened file-like object
diff --git a/pipenv/patched/piptools/resolver.py b/pipenv/patched/piptools/resolver.py
index 2906265..bf4dfcd 100644
--- a/pipenv/patched/piptools/resolver.py
+++ b/pipenv/patched/piptools/resolver.py
@@ -6,15 +6,14 @@ import copy
 from functools import partial
 from itertools import chain, count
 import os
-
 from first import first
-from pip.req import InstallRequirement
+from notpip.req import InstallRequirement
 
 from . import click
 from .cache import DependencyCache
 from .exceptions import UnsupportedConstraint
 from .logging import log
-from .utils import (format_requirement, format_specifier, full_groupby,
+from .utils import (format_requirement, format_specifier, full_groupby, dedup,
                     is_pinned_requirement, key_from_ireq, key_from_req, UNSAFE_PACKAGES)
 
 green = partial(click.style, fg='green')
@@ -28,6 +27,7 @@ class RequirementSummary(object):
     def __init__(self, ireq):
         self.req = ireq.req
         self.key = key_from_req(ireq.req)
+        self.markers = ireq.markers
         self.extras = str(sorted(ireq.extras))
         self.specifier = str(ireq.specifier)
 
@@ -68,9 +68,10 @@ class Resolver(object):
         """
         Finds acceptable hashes for all of the given InstallRequirements.
         """
-        return {ireq: self.repository.get_hashes(ireq) for ireq in ireqs}
+        with self.repository.allow_all_wheels():
+            return {ireq: self.repository.get_hashes(ireq) for ireq in ireqs}
 
-    def resolve(self, max_rounds=10):
+    def resolve(self, max_rounds=12):
         """
         Finds concrete package versions for all the given InstallRequirements
         and their recursive dependencies.  The end result is a flat list of
@@ -119,7 +120,7 @@ class Resolver(object):
     @staticmethod
     def check_constraints(constraints):
         for constraint in constraints:
-            if constraint.link is not None and not constraint.editable:
+            if constraint.link is not None and not constraint.editable and not constraint.is_wheel:
                 msg = ('pip-compile does not support URLs as packages, unless they are editable. '
                        'Perhaps add -e option?')
                 raise UnsupportedConstraint(msg, constraint)
@@ -148,6 +149,7 @@ class Resolver(object):
                 continue
 
             ireqs = iter(ireqs)
+
             # deepcopy the accumulator so as to not modify the self.our_constraints invariant
             combined_ireq = copy.deepcopy(next(ireqs))
             combined_ireq.comes_from = None
@@ -155,6 +157,7 @@ class Resolver(object):
                 # NOTE we may be losing some info on dropped reqs here
                 combined_ireq.req.specifier &= ireq.req.specifier
                 combined_ireq.constraint &= ireq.constraint
+                combined_ireq.markers = ireq.markers
                 # Return a sorted, de-duped tuple of extras
                 combined_ireq.extras = tuple(sorted(set(tuple(combined_ireq.extras) + tuple(ireq.extras))))
             yield combined_ireq
@@ -192,7 +195,6 @@ class Resolver(object):
         # Find the new set of secondary dependencies
         log.debug('')
         log.debug('Finding secondary dependencies:')
-
         safe_constraints = []
         for best_match in best_matches:
             for dep in self._iter_dependencies(best_match):
@@ -268,10 +270,21 @@ class Resolver(object):
         Editable requirements will never be looked up, as they may have
         changed at any time.
         """
+
         if ireq.editable:
             for dependency in self.repository.get_dependencies(ireq):
                 yield dependency
             return
+        elif ireq.markers:
+            for dependency in self.repository.get_dependencies(ireq):
+                dependency.prepared = False
+                yield dependency
+            return
+        elif ireq.extras:
+            for dependency in self.repository.get_dependencies(ireq):
+                dependency.prepared = False
+                yield dependency
+            return
         elif not is_pinned_requirement(ireq):
             raise TypeError('Expected pinned or editable requirement, got {}'.format(ireq))
 
@@ -282,14 +295,33 @@ class Resolver(object):
         if ireq not in self.dependency_cache:
             log.debug('  {} not in cache, need to check index'.format(format_requirement(ireq)), fg='yellow')
             dependencies = self.repository.get_dependencies(ireq)
-            self.dependency_cache[ireq] = sorted(str(ireq.req) for ireq in dependencies)
+            import sys
+            if sys.version_info[0] == 2:
+                self.dependency_cache[ireq] = sorted(format_requirement(ireq) for ireq in dependencies)
+            else:
+                self.dependency_cache[ireq] = sorted(format_requirement(ireq) for ireq in dependencies)
 
         # Example: ['Werkzeug>=0.9', 'Jinja2>=2.4']
         dependency_strings = self.dependency_cache[ireq]
         log.debug('  {:25} requires {}'.format(format_requirement(ireq),
                                                ', '.join(sorted(dependency_strings, key=lambda s: s.lower())) or '-'))
+        from notpip._vendor.packaging.markers import InvalidMarker
+
         for dependency_string in dependency_strings:
-            yield InstallRequirement.from_line(dependency_string, constraint=ireq.constraint)
+
+            try:
+                _dependency_string = dependency_string
+                if ';' in dependency_string:
+                    # split off markers and remove any duplicates by comparing against deps
+                    _dependencies = [dep.strip() for dep in dependency_string.split(';')]
+                    _dependency_string = '; '.join([dep for dep in dedup(_dependencies)])
+
+                yield InstallRequirement.from_line(_dependency_string, constraint=ireq.constraint)
+            except InvalidMarker:
+                yield InstallRequirement.from_line(dependency_string, constraint=ireq.constraint)
+
+
+
 
     def reverse_dependencies(self, ireqs):
         non_editable = [ireq for ireq in ireqs if not ireq.editable]
diff --git a/pipenv/patched/piptools/scripts/compile.py b/pipenv/patched/piptools/scripts/compile.py
index 5004e1b..2b30390 100644
--- a/pipenv/patched/piptools/scripts/compile.py
+++ b/pipenv/patched/piptools/scripts/compile.py
@@ -7,8 +7,8 @@ import os
 import sys
 import tempfile
 
-import pip
-from pip.req import InstallRequirement, parse_requirements
+import pip9
+from pip9.req import InstallRequirement, parse_requirements
 
 from .. import click
 from ..exceptions import PipToolsError
@@ -25,7 +25,7 @@ assert_compatible_pip_version()
 DEFAULT_REQUIREMENTS_FILE = 'requirements.in'
 
 
-class PipCommand(pip.basecommand.Command):
+class PipCommand(pip9.basecommand.Command):
     name = 'PipCommand'
 
 
@@ -244,12 +244,12 @@ def cli(verbose, dry_run, pre, rebuild, find_links, index_url, extra_index_url,
 
 
 def get_pip_command():
-    # Use pip's parser for pip.conf management and defaults.
+    # Use pip's parser for pip9.conf management and defaults.
     # General options (find_links, index_url, extra_index_url, trusted_host,
-    # and pre) are defered to pip.
+    # and pre) are defered to pip9.
     pip_command = PipCommand()
-    index_opts = pip.cmdoptions.make_option_group(
-        pip.cmdoptions.index_group,
+    index_opts = pip9.cmdoptions.make_option_group(
+        pip9.cmdoptions.index_group,
         pip_command.parser,
     )
     pip_command.parser.insert_option_group(0, index_opts)
diff --git a/pipenv/patched/piptools/scripts/sync.py b/pipenv/patched/piptools/scripts/sync.py
index e1d7f5e..d8c6d2c 100644
--- a/pipenv/patched/piptools/scripts/sync.py
+++ b/pipenv/patched/piptools/scripts/sync.py
@@ -5,7 +5,7 @@ from __future__ import (absolute_import, division, print_function,
 import os
 import sys
 
-import pip
+import pip9
 
 from .. import click, sync
 from ..exceptions import PipToolsError
@@ -47,7 +47,7 @@ def cli(dry_run, force, find_links, index_url, extra_index_url, no_index, quiet,
             log.error('ERROR: ' + msg)
             sys.exit(2)
 
-    requirements = flat_map(lambda src: pip.req.parse_requirements(src, session=True),
+    requirements = flat_map(lambda src: pip9.req.parse_requirements(src, session=True),
                             src_files)
 
     try:
@@ -56,7 +56,7 @@ def cli(dry_run, force, find_links, index_url, extra_index_url, no_index, quiet,
         log.error(str(e))
         sys.exit(2)
 
-    installed_dists = pip.get_installed_distributions(skip=[])
+    installed_dists = pip9.get_installed_distributions(skip=[])
     to_install, to_uninstall = sync.diff(requirements, installed_dists)
 
     install_flags = []
diff --git a/pipenv/patched/piptools/utils.py b/pipenv/patched/piptools/utils.py
index 35317f0..26d418e 100644
--- a/pipenv/patched/piptools/utils.py
+++ b/pipenv/patched/piptools/utils.py
@@ -6,8 +6,8 @@ import sys
 from itertools import chain, groupby
 from collections import OrderedDict
 
-import pip
-from pip.req import InstallRequirement
+import pip9
+from pip9.req import InstallRequirement
 
 from first import first
 
@@ -21,7 +21,7 @@ def safeint(s):
         return 0
 
 
-pip_version_info = tuple(safeint(digit) for digit in pip.__version__.split('.'))
+pip_version_info = tuple(safeint(digit) for digit in pip9.__version__.split('.'))
 
 UNSAFE_PACKAGES = {'setuptools', 'distribute', 'pip'}
 
@@ -30,7 +30,7 @@ def assert_compatible_pip_version():
     # Make sure we're using a reasonably modern version of pip
     if not pip_version_info >= (8, 0):
         print('pip-compile requires at least version 8.0 of pip ({} found), '
-              'perhaps run `pip install --upgrade pip`?'.format(pip.__version__))
+              'perhaps run `pip install --upgrade pip`?'.format(pip9.__version__))
         sys.exit(4)
 
 
@@ -59,16 +59,21 @@ def comment(text):
     return style(text, fg='green')
 
 
-def make_install_requirement(name, version, extras, constraint=False):
+def make_install_requirement(name, version, extras, markers, constraint=False):
     # If no extras are specified, the extras string is blank
     extras_string = ""
     if extras:
         # Sort extras for stability
         extras_string = "[{}]".format(",".join(sorted(extras)))
 
-    return InstallRequirement.from_line(
-        str('{}{}=={}'.format(name, extras_string, version)),
-        constraint=constraint)
+    if not markers:
+        return InstallRequirement.from_line(
+            str('{}{}=={}'.format(name, extras_string, version)),
+            constraint=constraint)
+    else:
+        return InstallRequirement.from_line(
+            str('{}{}=={}; {}'.format(name, extras_string, version, str(markers))),
+            constraint=constraint)
 
 
 def format_requirement(ireq, marker=None):
@@ -82,7 +87,7 @@ def format_requirement(ireq, marker=None):
         line = str(ireq.req).lower()
 
     if marker:
-        line = '{} ; {}'.format(line, marker)
+        line = '{}; {}'.format(line, marker)
 
     return line
 
